{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 회귀(Regression)\n",
    "\n",
    "예측할 값(Target)이 연속형(continuous) 데이터(float)인 지도 학습(Supervised Learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 회귀의 주요 평가 지표\n",
    "\n",
    "- ### MSE (Mean Squared Error)\n",
    "    - 실제 값과 예측값의 차를 제곱해 평균 낸 것\n",
    "    - scikit-learn 평가함수: mean_squared_error() \n",
    "    - 교차검증시 지정할 문자열: 'neg_mean_squared_error'\n",
    "    $$\n",
    "    MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2\\\\\n",
    "    y_i: 실제값, \\hat{y_i}: 모델이 예측한 값\n",
    "    $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ### RMSE (Root Mean Squared Error)\n",
    "    - MSE는 오차의 제곱한 값이므로 실제 오차의 평균보다 큰 값이 나온다.  MSE의 제곱근이 RMSE이다.\n",
    "    - mean_squared_error() 의 squared=False로 설정해서 계산. 또는 MSE를 구한 뒤 np.sqrt()로 제곱근을 구한다.\n",
    "    - 교차검증시 지정할 문자열: 'neg_root_mean_squared_error'\n",
    "    \n",
    "    $$\n",
    "    RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ### $R^2$ (R square, 결정계수)\n",
    "    - 평균으로 예측했을 때 오차(총오차) 보다 모델을 사용했을 때 얼마 만큼 더 좋은 성능을 내는지를 비율로 나타낸 값. \n",
    "    - 1에 가까울 수록 좋은 모델.\n",
    "    - scikit-learn 평가함수: r2_score()\n",
    "    - 교차검증시 지정할 문자열: 'r2'\n",
    "    - [참고](https://ko.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/r-squared-intuition)\n",
    "    $$\n",
    "    R^2 = \\cfrac{\\sum_{i=1}^{n}(\\hat{y_i}-\\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\\\\\n",
    "    R^2 = 1 - \\cfrac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n",
    "    $$\n",
    "\n",
    "- $y_i$ : i번째 정답 값, \n",
    "- $\\hat{y_i}$ : i 번째 예측 값, \n",
    "- $\\bar{y}$ : y의 평균    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:26.562987Z",
     "start_time": "2022-09-16T05:32:25.779804Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Dataset 생성\n",
    "- make_xxxxx() 함수\n",
    "    - 머신러닝 학습을 위한 dummy dataset 구현 함수\n",
    "    - 필요한 설정을 직접하여 테스트할 수 있는 데이터셋을 생성해준다.\n",
    "- make_regression(): 회귀 문제를 위한 dummy dataset 생성\n",
    "- make_classification(): 분류 문제를 위한 dummy dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:34.230063Z",
     "start_time": "2022-09-16T05:32:34.210281Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000,  # 데이터 개수\n",
    "                       n_features=1,  # feature(컬럼, X)의 개수\n",
    "                       n_informative=1,   # label(target, y)에 영향을 주는 feature 개수. feature개수보다 작거나 같은 정수지정.\n",
    "                       noise=30,  # 잡음->인정할 수 있는 오차범위. 모델이 찾을 수없는 값의 범위지정. 모델이 만든 값에 0 ~ 30 범위의 난수를 더한다.\n",
    "                       random_state=0\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:34.587837Z",
     "start_time": "2022-09-16T05:32:34.570330Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:35.319530Z",
     "start_time": "2022-09-16T05:32:35.305462Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Noise란 \n",
    ">  같은 Feature를 가진 데이터포인트가 다른 label을 가지는 이유를 Noise(노이즈)라고 한다. 단 그 이유는 현재 상태에선 모른다. 예를 들어 나이란 Feature가 있고 구매량이란 target이 있을때 같은 나이인데 구매량이 다른 경우 그 이유를 우리는 알 수 없다. 그 차이를 만드는 나이 이외의 Feature가 있는데 그것이 수집이 되지 않은 것이다.  그래서 데이터 수집하고 전처리 할 때 그 이유가 되는 Feature를 찾아야 한다. 찾으면 성능이 올라가는 것이고 못찾으면 모르는 이유가 되어 모델 성능이 떨어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:36.458029Z",
     "start_time": "2022-09-16T05:32:36.298090Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:36.816007Z",
     "start_time": "2022-09-16T05:32:36.802963Z"
    }
   },
   "outputs": [],
   "source": [
    "# 상관계수\n",
    "print(\"x, y의 상관계수\\n\", np.corrcoef(X.flatten(), y))\n",
    "print('y평균:', np.mean(y), \"y중앙값\", np.median(y), \"y최소/최대값\", np.min(y), np.max(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 생성, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:37.828362Z",
     "start_time": "2022-09-16T05:32:37.793804Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "# 선형회귀 모델. X와 y간에 상관성이 높을때 사용하며 직선의 방정식을 이용해 추론모델을 만든다.\n",
    "\n",
    "lr = LinearRegression()   # 기울기 * X + 절편  => 기울기와 절편을 학습시 찾는다.\n",
    "lr.fit(X, y)\n",
    "pred = lr.predict(X)  \n",
    "print(pred[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:38.712183Z",
     "start_time": "2022-09-16T05:32:38.697738Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y, pred))  \n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y, pred)), mean_squared_error(y, pred, squared=False))\n",
    "print(\"R2:\", r2_score(y, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 교차검증 (cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:41.324379Z",
     "start_time": "2022-09-16T05:32:39.489035Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(), GridSearchCV(), RandomizedSearchCV()\n",
    "score = cross_val_score(LinearRegression(), # 모델\n",
    "                        X, #Feature\n",
    "                        y, #target, \n",
    "                        scoring=\"neg_mean_squared_error\",   # -1 * MSE\n",
    "                        cv=5, #나눌 폴드 개수\n",
    "                        n_jobs=-1\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:41.418568Z",
     "start_time": "2022-09-16T05:32:41.408243Z"
    }
   },
   "outputs": [],
   "source": [
    "print(-1 * score)\n",
    "np.mean(-1*score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델이 찾은 계수(coef, 가중치-weigth)와 절편(intercept, 편향-bias) 조회\n",
    "- LinearRegression 모델이 학습해서 찾는 파라미터 제공 attribute\n",
    "    - coef_: Feature에 곱하는 가중치\n",
    "    - intercept_: 모든 Feature가 0일때 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:41.527943Z",
     "start_time": "2022-09-16T05:32:41.514183Z"
    }
   },
   "outputs": [],
   "source": [
    "print('기울기(coef, 가중치):', lr.coef_)\n",
    "print('절편(intercept, bias(편향)):', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:42.117879Z",
     "start_time": "2022-09-16T05:32:42.105226Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred[:5].flatten() )\n",
    "print(pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:42.583031Z",
     "start_time": "2022-09-16T05:32:42.560637Z"
    }
   },
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:42.829485Z",
     "start_time": "2022-09-16T05:32:42.808685Z"
    }
   },
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### X, y와 추론결과  시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:43.219270Z",
     "start_time": "2022-09-16T05:32:43.123233Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y, alpha=0.3)  # X와 정답간의 관계\n",
    "y_hat = lr.predict(X)  # X*lr.coef_ + lr.intercept_  # X와 모델이 추론한값\n",
    "plt.plot(X, y_hat, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 기존 분류 모델의 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:44.228663Z",
     "start_time": "2022-09-16T05:32:44.216980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XXXXXClassifier: 분류,  XXXXXRegressor : 회귀\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# 회귀 데이터셋: stratify를 지정하지 않는다.\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 모델들 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:45.998875Z",
     "start_time": "2022-09-16T05:32:45.977883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "tree = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "rfr = RandomForestRegressor(n_estimators=200, max_depth=2)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, max_depth=2)\n",
    "lr = LinearRegression()\n",
    "xgb = XGBRegressor(n_estimators=200, max_depth=2, learning_rate=0.01)\n",
    "\n",
    "estimators = [\n",
    "    ('knn', knn),\n",
    "    ('Tree', tree),\n",
    "    ('Random Forest', rfr),\n",
    "    ('gradient boosting', gb),\n",
    "    ('Linear Regression', lr),\n",
    "    ('XGBoost', xgb)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 평가출력 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:47.775804Z",
     "start_time": "2022-09-16T05:32:47.732146Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile metrics.py\n",
    "# %load metrics.py\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, PrecisionRecallDisplay, roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 회귀문제 평가함수\n",
    "def print_metrics_regression(y, pred, title=None):\n",
    "    \"\"\"\n",
    "    회귀문제 평가지표를 출력하는 함수\n",
    "    MSE, RMSE, R2 세개의 평가지표를 출력\n",
    "    [parameter]\n",
    "        y: ndarray - 정답(target)\n",
    "        pred: ndarray - 모델이 추론한 결과\n",
    "        title: str - 출력할 내용의 title. 기본값: None = 출력안한다.\n",
    "    [return value]\n",
    "    [exception]\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print(title)\n",
    "    mse = mean_squared_error(y, pred)\n",
    "    rmse = mean_squared_error(y, pred, squared=False)\n",
    "    r2 = r2_score(y, pred)\n",
    "    print(f'MSE: {mse}, RMSE: {rmse}, R2: {r2}')\n",
    "\n",
    "# 분류문제 평가 함수\n",
    "def print_metrics_classification(y, pred, title=None):\n",
    "    \"\"\"\n",
    "    정답(target)과 모델이 추론한 값을 받아 정확도, 재현율, 정밀도, f1 점수를 출력\n",
    "    [parameter]\n",
    "        y: ndarray - 정답(target)\n",
    "        pred: ndarray - 모델이 추론한 결과\n",
    "        title: str - 출력할 내용의 title. 기본값: None = 출력안한다.\n",
    "    [return value]\n",
    "    [exception]\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print(title)\n",
    "    print(f'정확도(accuracy): {accuracy_score(y, pred)}, 재현율(recall):{recall_score(y, pred)}, 정밀도(precision):{precision_score(y, pred)}, F1점수:{f1_score(y, pred)}')\n",
    "\n",
    "def plot_confusionmatrix(y, pred, title=None):\n",
    "    \"\"\"\n",
    "    정답과 모델이 추론한 결과를 이용해 Confusion Matrix를 시각화(히트맵)하는 함수\n",
    "    [parameter]\n",
    "        y: ndarray - 정답(target)\n",
    "        pred: ndarray - 모델이 추론한 결과\n",
    "        title: str - 출력할 내용의 title. 기본값: None = 출력안한다.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y, pred)\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_precisionrecall_curve(y, pos_proba, title=None):\n",
    "    \"\"\"\n",
    "    Precision Recall Curve 를 시각화하는 함수\n",
    "    [parameter]\n",
    "        y: ndarray - 정답\n",
    "        pos_proba: ndarray - positive(양성)의 확률\n",
    "        title: str - 출력할 내용의 title\n",
    "    \"\"\"\n",
    "    ap_score = average_precision_score(y, pos_proba)\n",
    "    precisions, recalls, threshs = precision_recall_curve(y, pos_proba)\n",
    "    disp = PrecisionRecallDisplay(precisions, recalls, average_precision=ap_score)\n",
    "    disp.plot()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roccurve(y, pos_proba, title=None):\n",
    "    \"\"\"\n",
    "    ROC Curve를 시각화하는 함수\n",
    "    [parameter]\n",
    "        y: ndarry - 정답\n",
    "        pos_proba: ndarray - positive(양성)의 확률\n",
    "        title: str - 출력할 내용의 title\n",
    "    \"\"\"\n",
    "    auc_score = roc_auc_score(y, pos_proba)\n",
    "    fprs, tprs, threshs = roc_curve(y, pos_proba)\n",
    "    disp = RocCurveDisplay(fpr=fprs, tpr=tprs, roc_auc=auc_score)\n",
    "    disp.plot()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:51.118105Z",
     "start_time": "2022-09-16T05:32:51.090183Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import print_metrics_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-16T05:32:52.465175Z",
     "start_time": "2022-09-16T05:32:52.449853Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_metrics_regression(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:16:40.833073Z",
     "start_time": "2022-09-14T03:16:40.480301Z"
    }
   },
   "outputs": [],
   "source": [
    "for model_name, model in estimators:\n",
    "#     학습\n",
    "    model.fit(X_train, y_train)\n",
    "#     추론\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "#     평가\n",
    "    print_metrics_regression(y_train, pred_train, f\"{model_name}의 Train set 평가\")\n",
    "    print_metrics_regression(y_test, pred_test, f\"{model_name}의 Test set 평가\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Voting\n",
    "- VotingRegressor \n",
    "    - 각 모델이 예측한 값의 평균을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:23:38.878509Z",
     "start_time": "2022-09-14T03:23:38.513147Z"
    }
   },
   "outputs": [],
   "source": [
    "voting = VotingRegressor(estimators=estimators)\n",
    "voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:24:29.434462Z",
     "start_time": "2022-09-14T03:24:29.373992Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_train2 = voting.predict(X_train)\n",
    "pred_test2 = voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:24:39.321917Z",
     "start_time": "2022-09-14T03:24:39.310566Z"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics_regression(y_train, pred_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:24:58.465564Z",
     "start_time": "2022-09-14T03:24:58.447014Z"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics_regression(y_test, pred_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### DecisionTreeRegressor Tree 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T03:29:04.579158Z",
     "start_time": "2022-09-14T03:29:04.221201Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "graph = Source(export_graphviz(tree, \n",
    "#                                feature_names=xxx,\n",
    "                               rounded=True, \n",
    "                               filled=True                          \n",
    "                              ))\n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8ea266b9a32e539376479ecefb4b43de94cddfc186952a2290bc119c664ac37e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
